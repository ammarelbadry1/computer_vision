{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from matplotlib import pyplot as plt\n","import numpy as np\n","import cv2 as cv"]},{"cell_type":"markdown","metadata":{},"source":["# Reading and Loading Images"]},{"cell_type":"markdown","metadata":{},"source":["- Read the image\n","- Processing it\n","- Showing it\n","- Saving it"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["image = cv.imread(\"./gotham.jpg\")\n","gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n","cv.imshow(\"Color Image\", image)\n","cv.imshow(\"Gray Image\", gray_image)\n","cv.imwrite(\"./gotham_gray.jpg\", gray_image)\n","cv.waitKey(0)\n","cv.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{},"source":["# Accessing and Manipulating Pixels"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["the pixel value at the position y=200, x=250  =>  [18 13 22]\n"]}],"source":["# read the image\n","image = cv.imread(\"./gotham.jpg\")\n","\n","# access a specific pixel using the coordinate based access from the matrix\n","pixel = image[200, 250]\n","\n","#see what color space this pixel represents - this is an RBG representation\n","print(\"the pixel value at the position y=200, x=250  => \", pixel)\n","\n","# change the pixel color\n","image[200, 250] = (0, 255, 0)\n","\n","cv.imshow(\"one pixel\",image)\n","cv.waitKey(0)\n","cv.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# change the pixel color in a region range\n","image[200:250, 200:350] = (0, 255, 0)\n","\n","cv.imshow(\"Manipulating pixel range\",image)\n","cv.waitKey(0)\n","cv.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{},"source":["# Shapes"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["image = cv.imread(\"./gotham.jpg\")\n","\n","# Drawing a line\n","cv.line(image, (26, 22), (200, 200), (0, 0, 255), 2)\n","cv.line(image, (26 ,200), (200, 26), (0, 0, 255), 2)\n","# Drawing a rectangle\n","cv.rectangle(image, (26, 22), (200, 200), (0, 0, 255), 2)\n","# Drawing a circle\n","cv.circle(image, (113, 111), 50, (0, 0, 255), 2)\n","\n","cv.imshow(\"gotham\", image)\n","cv.waitKey(0)\n","cv.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{},"source":["# Filtering Images"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Blurring\n","image = cv.imread(\"./gotham.jpg\")\n","\n","noise_reduced_version = cv.medianBlur(image, 3)\n","cv.imshow(\"Blurred with a filter of size 3\", noise_reduced_version)\n","\n","cv.imshow(\"Original Image\", image)\n","cv.waitKey(0)\n","cv.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{},"source":["# Transforming Images"]},{"cell_type":"markdown","metadata":{},"source":["### Translation"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["image = cv.imread(\"./gotham.jpg\")\n","\n","num_rows, num_cols = image.shape[:2]\n","\n","translation_matrix = np.float32([ [1, 0, 70], [0, 1, 110] ])\n","image_translation = cv.warpAffine(image, translation_matrix, (num_cols, num_rows))\n","\n","cv.imshow(\"Translation\", image_translation)\n","cv.waitKey(0)\n","cv.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{},"source":["### Rotation"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["image = cv.imread(\"./gotham.jpg\")\n","\n","num_rows, num_cols = image.shape[:2]\n","\n","rotation_matrix = cv.getRotationMatrix2D((0.5 * num_cols, 0.5 * num_rows), 20, 0.5)\n","image_rotation = cv.warpAffine(image, rotation_matrix, (num_cols, num_rows))\n","\n","cv.imshow(\"Rotated Image\", image_rotation)\n","cv.waitKey(0)\n","cv.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{},"source":["### Scaling"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["image = cv.imread(\"./gotham.jpg\")\n","\n","scale1 = cv.resize(image, None, fx=1.2, fy=1.2, interpolation=cv.INTER_LINEAR)\n","cv.imshow('Scaling - Linear Interpolation', scale1)\n","\n","scale2 = cv.resize(image, None, fx=1.2, fy=1.2, interpolation=cv.INTER_CUBIC)\n","cv.imshow('Scaling - Cubic Interpolation', scale2)\n","\n","scale3 = cv.resize(image, (450, 400), interpolation=cv.INTER_AREA)\n","cv.imshow(\"Scaling in different window size\", scale3)\n","\n","cv.waitKey(0)\n","cv.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{},"source":["# Edge Detection"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["image = cv.imread(\"./gotham.jpg\")\n","\n","edges = cv.Canny(image, 100, 200)\n","\n","cv.imshow(\"Edges\", edges)\n","cv.waitKey(0)\n","cv.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{},"source":["# Image Segmentation"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of contours found =  378\n"]}],"source":["image = cv.imread(\"./gotham.jpg\")\n","\n","gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n","edges = cv.Canny(gray, 10, 200)\n","contours, hierarchy = cv.findContours(edges, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)\n","print(\"Number of contours found = \", len(contours))\n","cv.drawContours(image, contours, -1, (0, 255, 0), 1)\n","\n","cv.imshow(\"Image with Contours\", image)\n","cv.waitKey(0)\n","cv.destroyAllWindows()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Line Detection"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["image = cv.imread(\"./chessboard.jpg\")\n","\n","# This line just to fit the output window on my screen - Not a part of the code block\n","image = cv.resize(image, (1280, 700), interpolation=cv.INTER_AREA)\n","\n","gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n","image_edges = cv.Canny(gray_image, 100, 170, apertureSize=3)\n","lines = cv.HoughLines(image_edges, 1, np.pi / 180, 240)\n","\n","for rho, theta in lines[0]:\n","    a = np.cos(theta)\n","    b = np.sin(theta)\n","    x0 = a * rho\n","    y0 = b * rho\n","    x1 = int(x0 + 1000 * (-b))\n","    y1 = int(y0 + 1000 * (a))\n","    x2 = int(x0 - 1000 * (-b))\n","    y2 = int(y0 - 1000 * (a))\n","    cv.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n","\n","cv.imshow(\"ChessBoard Edges\", image)\n","cv.waitKey(0)\n","cv.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{},"source":["# Circle Detection"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["image = cv.imread(\"./bottlecap1.jpg\")\n","\n","gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n","blurred_image = cv.medianBlur(gray_image, 5)\n","circles = cv.HoughCircles(blurred_image, cv.HOUGH_GRADIENT, 1.5, 10)\n","\n","circles = np.uint16(np.around(circles))\n","\n","for i in circles[0, :]:\n","    cv.circle(image, (i[0], i[1]), i[2], (0, 0, 255), 2)\n","    cv.circle(image, (i[0], i[1]), 2, (0, 255, 0), 5)\n","\n","cv.imshow(\"Detected Circles\", image)\n","cv.waitKey(0)\n","cv.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{},"source":["# Object Detection"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["carscene = cv.imread(\"./carscene.jpg\")\n","gray_carscene = cv.cvtColor(carscene, cv.COLOR_BGR2GRAY)\n","\n","# This line just to fit the output window on my screen - Not a part of the code block\n","carscene = cv.resize(carscene, (724, 1024), interpolation=cv.INTER_AREA)\n","\n","car = cv.imread(\"./car.jpg\")\n","gray_car = cv.cvtColor(car, cv.COLOR_BGR2GRAY)\n","\n","result = cv.matchTemplate(car, carscene, cv.TM_CCOEFF)\n","min_val, max_val, min_loc, max_loc = cv.minMaxLoc(result)\n","\n","# Create Bounding Box\n","top_left = max_loc\n","# bottom_right = (top_left[0] + (max_loc[1] - min_loc[1]), top_left[1] + (max_loc[0] - min_loc[0]))\n","bottom_right = (top_left[0] + 450, top_left[1] + 150) # Hard coded values ðŸ™„?\n","cv.rectangle(carscene, top_left, bottom_right, (0, 255, 0), 3)\n","\n","# cv.imshow(\"Car\", car)\n","cv.imshow(\"Car Scene\", carscene)\n","cv.waitKey(0)\n","cv.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{},"source":["# Harris Corner Detection"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["image = cv.imread(\"./chessboard.jpg\")\n","\n","# This line just to fit the output window on my screen - Not a part of the code block\n","image = cv.resize(image, (1280, 700), interpolation=cv.INTER_AREA)\n","\n","gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n","gray_image = np.float32(gray_image)\n","\n","corners = cv.cornerHarris(gray_image, 2, 3, 0.04)\n","\n","corners2 = cv.dilate(corners, None, iterations=3)\n","image[corners2 > 0.01 * corners2.max()] = [0, 0, 255]\n","\n","cv.imshow(\"Corners\", corners)\n","cv.imshow(\"Original Image with corners\", image)\n","cv.waitKey(0)\n","cv.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{},"source":["# Scale Variant Feature Transform"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of keypoints detected: 1178\n"]}],"source":["image = cv.imread(\"./gotham.jpg\")\n","gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n","\n","sift = cv.SIFT_create()\n","keypoints = sift.detect(image, None)\n","print(\"Number of keypoints detected:\", len(keypoints))\n","\n","cv.drawKeypoints(image, keypoints, image, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n","\n","cv.imshow(\"Feature Method - SIFT\", image)\n","cv.waitKey(0)\n","cv.destroyAllWindows()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Speeded-Up Robust Features"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"module 'cv2' has no attribute 'SURF_create'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[17], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m image \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./gotham.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m gray_image \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mcvtColor(image, cv\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m----> 4\u001b[0m surf \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSURF_create\u001b[49m()\n\u001b[0;32m      5\u001b[0m surf\u001b[38;5;241m.\u001b[39mhessianThreshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[0;32m      7\u001b[0m keypoints, descriptors \u001b[38;5;241m=\u001b[39m surf\u001b[38;5;241m.\u001b[39mdetectAndCompute(gray_image, \u001b[38;5;28;01mNone\u001b[39;00m)\n","\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'SURF_create'"]}],"source":["image = cv.imread(\"./gotham.jpg\")\n","gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n","\n","surf = cv.SURF_create()\n","surf.hessianThreshold = 500\n","\n","keypoints, descriptors = surf.detectAndCompute(gray_image, None)\n","print(\"Number of keypoints detected: \", len(keypoints))\n","\n","image = cv.drawKeypoints(image, keypoints, None, flags=cv.DRAWMATCHESFLAGS_DRAW_RICH_KEYPOINTS)\n","\n","cv.imshow(\"Speeded-Up Robust Features Detection\", image)\n","cv.waitkey(0)\n","cv.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{},"source":["# Features from Accelerated Segment Test"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of keypoints detected: 3823\n"]}],"source":["image = cv.imread(\"./gotham.jpg\")\n","gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n","\n","fast = cv.FastFeatureDetector_create()\n","\n","keypoints = fast.detect(gray_image, None)\n","print(\"Number of keypoints detected:\", len(keypoints))\n","image = cv.drawKeypoints(image, keypoints, None, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n","\n","cv.imshow(\"Detect Features from Accelerated Segment Test\", image)\n","cv.waitKey(0)\n","cv.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{},"source":["# Binary Robust Independent Elementary Features"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of keypoints detected:  3710\n"]}],"source":["image = cv.imread(\"./gotham.jpg\")\n","gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n","\n","fast = cv.FastFeatureDetector_create()\n","brief = cv.xfeatures2d.BriefDescriptorExtractor_create()\n","\n","keypoints = fast.detect(gray_image, None)\n","keypoints, descriptors = brief.compute(gray_image, keypoints)\n","print(\"Number of keypoints detected: \", len(keypoints))\n","image = cv.drawKeypoints(image, keypoints, None, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n","\n","cv.imshow(\"Feature Method - BRIEF\", image)\n","cv.waitKey()\n","cv.destroyAllWindows()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Oriented FAST and Rotated BRIEF"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of keypoints detected:  500\n"]}],"source":["image = cv.imread(\"./gotham.jpg\")\n","gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n","\n","orb = cv.ORB_create()\n","keypoints = orb.detect(gray_image, None)\n","keypoints, descriptors = orb.compute(gray_image, keypoints)\n","print(\"Number of keypoints detected: \", len(keypoints))\n","image = cv.drawKeypoints(image, keypoints, None, flags=0)\n","\n","cv.imshow(\"Oriented FAST and Rotated BRIEF\", image)\n","cv.waitKey(0)\n","cv.destroyAllWindows()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":2}
